{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutoCorrection.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPPnKgSBe+lNjamZFjHv+AR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nourhan-Adell/Natural-language-processing/blob/main/AutoCorrection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **AutoCorrection Project**\n",
        "\n",
        "## Agenda:\n",
        "\n",
        "\n",
        "*   Steps for implementing autocorrect system:\n",
        "1.   Identify the misspelled word.\n",
        "2.   Find strings that are n edit distance away from misspelled word.\n",
        "3.   Filter suggested candidates to return only the ones found in vocabulary.\n",
        "4.   Order filtered candidates based on word probabilities.\n",
        "5.   Choose the most likely candidate.\n",
        "\n",
        "---\n",
        "**Illustration:**\n",
        "\n",
        "*   Misspelled word: is the word that is not found in the Vocabulary.\n",
        "\n",
        "\n",
        "*   Second step: we make some operations as:(Delete, Swap, Replace, Insert).\n",
        "\n",
        "\n",
        "*   Calculating word probability = Count(word)/sum(corpus's words).\n",
        "\n",
        "\n",
        "*   Minimum edit distance: is the least number of edits needed to transform one string into another\n",
        "*We will make this step after detecting the most probable correct word, After all previous steps.*\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rWuXXVzEhshy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Imort libraries:**"
      ],
      "metadata": {
        "id": "u09rqxhAohjt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vieeTtpEhQSl"
      },
      "outputs": [],
      "source": [
        "# Importing libraries\n",
        "import re     # Regular expression library\n",
        "import string\n",
        "from collections import Counter \n",
        "import numpy as np "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Preprocessiong steps**"
      ],
      "metadata": {
        "id": "zSfyd4csoqJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_corpus(file_name):\n",
        "  with open(file_name, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "    words = []\n",
        "\n",
        "    for line in lines:\n",
        "      words += re.findall(r'\\w+', line.lower())\n",
        "\n",
        "  return words"
      ],
      "metadata": {
        "id": "a7Xx6WZKl6q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = read_corpus(\"/content/shakespeare.txt\")\n",
        "print(\"Length of words in the corpus: \", {len(words)})      # It's total number words in the corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49nU3N8bnNlQ",
        "outputId": "1ac36994-0335-40ae-ae05-f18e90723b39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of words in the corpus:  {53614}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabs = set(words)\n",
        "print(\"The length of unique words in the corpus: \", len(vocabs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBUQz6IDnn9M",
        "outputId": "adc37d43-b20c-41a2-edc7-73a17e80ecec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of unique words in the corpus:  6116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words_count = Counter(words)      # it calculate the number of times that tjhe word appeared in the corpus\n",
        "print(f\"The love word is repeated {words_count['love']} times in the corpus\")        # We will use it in calculating the probabilities of the words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyTzytOro_xu",
        "outputId": "1a21e811-aea4-43fd-edfc-701037b0cfe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The love word is repeated 279 times in the corpus\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Calculate word probabilities:**"
      ],
      "metadata": {
        "id": "e46ewOnuqN70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_word_count = float(sum(words_count.values()))     #float: to be more accurate in division process\n",
        "word_probs = {word: words_count[word] / total_word_count for word in words_count.keys() }\n"
      ],
      "metadata": {
        "id": "EchtOi5MpPrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test:\n",
        "print(word_probs['love'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8Cb8txsq9ae",
        "outputId": "8ff1116d-c5d1-4a30-c9e9-3eb53e4eaf90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.005203864662215093\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Second step (Operations):**"
      ],
      "metadata": {
        "id": "-MMoXrsAs3q_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split(word):\n",
        "  return [(word[:i], word[i:]) for i in range(len(word) + 1) ]\n",
        "print(\"Split process: \", split('love'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvdH8AN8rLmZ",
        "outputId": "4f9fc983-7544-4aaa-806e-b6308364702b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split process:  [('', 'love'), ('l', 'ove'), ('lo', 've'), ('lov', 'e'), ('love', '')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.Delete function"
      ],
      "metadata": {
        "id": "EQCLHUAztnZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def delete(word):\n",
        "  return [l + r[1:] for l,r in split(word) if r]     # delete the letter in index 0 for the right side in the split function\n",
        "\n",
        "print(delete('love'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08eVgY3ltUp1",
        "outputId": "e3788adb-da92-4188-eb28-f6eb436f740f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ove', 'lve', 'loe', 'lov']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.Swap function:"
      ],
      "metadata": {
        "id": "9uQi8z0Cupm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def swap(word):\n",
        "  return [l + r[1] + r[0] + r[2:] for l,r in split(word) if len(r) > 1]\n",
        "print(swap('love'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTNbENXZubmc",
        "outputId": "72454716-445c-4512-ed83-7d0d25c36004"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['olve', 'lvoe', 'loev']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.Replace function:"
      ],
      "metadata": {
        "id": "xY3Aq_tmv2hA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def replace(word):\n",
        "  letters = string.ascii_lowercase\n",
        "  return [l + c + r[1:] for l,r in split(word) if r for c in letters ]\n",
        "\n",
        "print(replace('love'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1bDRSkGvG-7",
        "outputId": "22df3b05-8837-4fce-8180-cf96dbe81d68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['aove', 'bove', 'cove', 'dove', 'eove', 'fove', 'gove', 'hove', 'iove', 'jove', 'kove', 'love', 'move', 'nove', 'oove', 'pove', 'qove', 'rove', 'sove', 'tove', 'uove', 'vove', 'wove', 'xove', 'yove', 'zove', 'lave', 'lbve', 'lcve', 'ldve', 'leve', 'lfve', 'lgve', 'lhve', 'live', 'ljve', 'lkve', 'llve', 'lmve', 'lnve', 'love', 'lpve', 'lqve', 'lrve', 'lsve', 'ltve', 'luve', 'lvve', 'lwve', 'lxve', 'lyve', 'lzve', 'loae', 'lobe', 'loce', 'lode', 'loee', 'lofe', 'loge', 'lohe', 'loie', 'loje', 'loke', 'lole', 'lome', 'lone', 'looe', 'lope', 'loqe', 'lore', 'lose', 'lote', 'loue', 'love', 'lowe', 'loxe', 'loye', 'loze', 'lova', 'lovb', 'lovc', 'lovd', 'love', 'lovf', 'lovg', 'lovh', 'lovi', 'lovj', 'lovk', 'lovl', 'lovm', 'lovn', 'lovo', 'lovp', 'lovq', 'lovr', 'lovs', 'lovt', 'lovu', 'lovv', 'lovw', 'lovx', 'lovy', 'lovz']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.Insert function:\n"
      ],
      "metadata": {
        "id": "RoYcHocIwdbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def insert(word):\n",
        "  letters = string.ascii_lowercase\n",
        "  return [l + c + r for l,r in split(word) for c in letters]\n",
        "\n",
        "print(insert('love'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBF38mspwaH5",
        "outputId": "66616dc9-2c0a-4e27-bbab-31a05aea9b17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['alove', 'blove', 'clove', 'dlove', 'elove', 'flove', 'glove', 'hlove', 'ilove', 'jlove', 'klove', 'llove', 'mlove', 'nlove', 'olove', 'plove', 'qlove', 'rlove', 'slove', 'tlove', 'ulove', 'vlove', 'wlove', 'xlove', 'ylove', 'zlove', 'laove', 'lbove', 'lcove', 'ldove', 'leove', 'lfove', 'lgove', 'lhove', 'liove', 'ljove', 'lkove', 'llove', 'lmove', 'lnove', 'loove', 'lpove', 'lqove', 'lrove', 'lsove', 'ltove', 'luove', 'lvove', 'lwove', 'lxove', 'lyove', 'lzove', 'loave', 'lobve', 'locve', 'lodve', 'loeve', 'lofve', 'logve', 'lohve', 'loive', 'lojve', 'lokve', 'lolve', 'lomve', 'lonve', 'loove', 'lopve', 'loqve', 'lorve', 'losve', 'lotve', 'louve', 'lovve', 'lowve', 'loxve', 'loyve', 'lozve', 'lovae', 'lovbe', 'lovce', 'lovde', 'lovee', 'lovfe', 'lovge', 'lovhe', 'lovie', 'lovje', 'lovke', 'lovle', 'lovme', 'lovne', 'lovoe', 'lovpe', 'lovqe', 'lovre', 'lovse', 'lovte', 'lovue', 'lovve', 'lovwe', 'lovxe', 'lovye', 'lovze', 'lovea', 'loveb', 'lovec', 'loved', 'lovee', 'lovef', 'loveg', 'loveh', 'lovei', 'lovej', 'lovek', 'lovel', 'lovem', 'loven', 'loveo', 'lovep', 'loveq', 'lover', 'loves', 'lovet', 'loveu', 'lovev', 'lovew', 'lovex', 'lovey', 'lovez']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Find best correction for the misspelled word**"
      ],
      "metadata": {
        "id": "gHfzHgxMxHBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def level_one_edit(word):\n",
        "  return set(delete(word) + swap(word) + replace(word) + insert(word))\n",
        "# here we make all operations possible to get all possible words\n",
        "\n",
        "print(level_one_edit('love'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AitXFOZWw17E",
        "outputId": "d42c3290-d872-44b8-b4cf-aac9ca647570"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'hove', 'looe', 'lolve', 'lovi', 'lovue', 'lovbe', 'lxve', 'cove', 'luve', 'klove', 'loee', 'lovke', 'lova', 'loye', 'lovs', 'lovie', 'loveq', 'olve', 'lovek', 'lovee', 'lotve', 'lfove', 'lovh', 'lovae', 'lxove', 'loxe', 'lovew', 'blove', 'lov', 'alove', 'eove', 'leve', 'lome', 'lovl', 'wove', 'lovef', 'yove', 'mlove', 'lzove', 'loev', 'lvve', 'lovge', 'loveb', 'lovei', 'loveu', 'lovez', 'kove', 'loqve', 'lose', 'slove', 'lcove', 'lsve', 'lovu', 'lowe', 'lovye', 'lave', 'ljve', 'flove', 'lovej', 'leove', 'lovce', 'lovem', 'lovze', 'lovp', 'lozve', 'lhove', 'lzve', 'clove', 'lcve', 'lovm', 'lovje', 'lyove', 'lvove', 'vlove', 'glove', 'elove', 'liove', 'lrve', 'loave', 'fove', 'lnve', 'lofe', 'jlove', 'loive', 'lovre', 'lovet', 'lopve', 'iove', 'loxve', 'lovpe', 'lole', 'lovn', 'loae', 'xlove', 'lofve', 'lve', 'loie', 'lovfe', 'loeve', 'nove', 'xove', 'lqove', 'lbove', 'olove', 'loce', 'lovhe', 'llove', 'lovev', 'lobve', 'lovo', 'losve', 'lovqe', 'lovd', 'lovse', 'uove', 'lovve', 'ltove', 'gove', 'lovea', 'lohe', 'lovep', 'loyve', 'lovwe', 'hlove', 'lwve', 'lovw', 'ldove', 'rlove', 'lovt', 'lovv', 'lovte', 'loveh', 'ulove', 'loze', 'loved', 'dove', 'sove', 'lmve', 'lgove', 'lover', 'lovq', 'ilove', 'lovme', 'vove', 'lovz', 'lokve', 'lovxe', 'loven', 'loge', 'lgve', 'lkove', 'dlove', 'loveg', 'lsove', 'lovk', 'ove', 'lwove', 'lodve', 'loqe', 'loveo', 'llve', 'lovg', 'lovle', 'lvoe', 'lbve', 'lpve', 'lkve', 'loves', 'locve', 'oove', 'lovex', 'lyve', 'laove', 'lovne', 'lovc', 'loje', 'loue', 'lovf', 'lpove', 'lovde', 'lovoe', 'lovb', 'ltve', 'lote', 'bove', 'zlove', 'lorve', 'lomve', 'nlove', 'lobe', 'loke', 'lovey', 'lope', 'move', 'qove', 'wlove', 'tove', 'lovy', 'live', 'lovec', 'jove', 'lfve', 'lovj', 'ljove', 'pove', 'lode', 'qlove', 'lrove', 'plove', 'lohve', 'lone', 'ylove', 'louve', 'loove', 'lowve', 'aove', 'tlove', 'lqve', 'luove', 'zove', 'rove', 'lovx', 'lore', 'loe', 'lojve', 'lhve', 'logve', 'love', 'lovr', 'lovel', 'lmove', 'ldve', 'lonve', 'lnove'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def level_two_edits(word):\n",
        "  return(e2 for e1 in level_one_edit(word) for e2 in level_one_edit(e1))\n",
        "  # we perform the level-one_edit twice"
      ],
      "metadata": {
        "id": "EgbsbZahyCgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Suggest the best correct word**"
      ],
      "metadata": {
        "id": "bwCB7ejVzAGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def correct_spelling(word, vocab, word_probs):\n",
        "  if word in vocab:\n",
        "    print(f\"The word {word} is correctly spelt\")\n",
        "    return\n",
        "  suggestion = level_one_edit(word) or level_two_edits(word) or [word]  \n",
        "  # If we have a good suggestion in level one we will not continue else we will continue to level 2 or return the \n",
        "  # word as it is, as here we have done only two levels of edit, there may be more than that...\n",
        "  best_guesses = [w for w in suggestion if w in vocab]\n",
        "  return [(w, word_probs[w]) for w in best_guesses]"
      ],
      "metadata": {
        "id": "agHZ5_y3yl0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word ='loee'\n",
        "guess = correct_spelling(word, vocabs, word_probs)\n",
        "print(guess)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i16FlGTQ0R7b",
        "outputId": "96ff848c-47ac-437c-c856-6857da17b572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('lose', 0.0005409034953556906), ('love', 0.005203864662215093)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word ='foad'\n",
        "guess = correct_spelling(word, vocabs, word_probs)\n",
        "print(guess)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MDLm2Rj24s2",
        "outputId": "d6a1c491-5216-48a5-bc2b-dff197446aca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('fold', 1.865184466743761e-05), ('road', 1.865184466743761e-05), ('food', 1.865184466743761e-05), ('fond', 9.325922333718805e-05)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sum up all the previous steps in one cell::)**"
      ],
      "metadata": {
        "id": "N5U3jjg13dOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SpellChecker(object):\n",
        "  def __init__(self, courpus_file_path):\n",
        "    with open(courpus_file_path, 'r') as file:\n",
        "      lines = file.readlines()\n",
        "      words = []\n",
        "      for line in lines:\n",
        "        words += re.findall(r'\\w+',line.lower())\n",
        "      \n",
        "      self.vocabs = set(words)\n",
        "      self.words_counts = Counter(words)\n",
        "      total_words = float(sum(self.words_counts.values()))\n",
        "      self.word_probs = {word: self.words_counts[word] / total_words for word in self.vocabs}\n",
        "\n",
        "  def _level_one_edit(self, word):\n",
        "      letters = string.ascii_lowercase\n",
        "      split = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
        "      delete = [l + r[1:] for l,r in split if r]\n",
        "      swap =[l + r[1] + r[0] + r[2:] for l,r in split if len(r) > 1]\n",
        "      replace = [l + c + r[1:] for l,r in split if r for c in letters]\n",
        "      insert = [l + c + r for l,r in split for c in letters]\n",
        "      return set(delete + swap + replace + insert)\n",
        "\n",
        "  def _level_two_edit(self, word):\n",
        "      return [e2 for e1 in self._level_one_edit(word) for e2 in self._level_one_edit(e1)]\n",
        "\n",
        "  def check(self, word):\n",
        "      candidate = self._level_one_edit(word) or self._level_two_edit(word) or [word]\n",
        "      valid_candidate = [w for w in candidate if w in self.vocabs]\n",
        "      return sorted([(c, self.word_probs[c]) for c in valid_candidate], key=lambda tup:tup[1], reverse=True)"
      ],
      "metadata": {
        "id": "1Kfp6vuv3Yqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checker = SpellChecker('/content/shakespeare.txt')"
      ],
      "metadata": {
        "id": "HzJBP0iV8XRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "misspelled_word  = 'sentense'\n",
        "print(checker.check(misspelled_word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABmTOPWA8eVE",
        "outputId": "484931f3-0d47-4ba7-ff0b-71a4a2f8602d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('sentence', 3.730368933487522e-05)]\n"
          ]
        }
      ]
    }
  ]
}
