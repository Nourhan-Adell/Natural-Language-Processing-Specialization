{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part_Of_Speech.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMOT1FdkooSQtXfYYgrjUAm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nourhan-Adell/Natural-language-processing/blob/main/Part_Of_Speech.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part of speech tagging**\n",
        "Distinguishing the parts-of-speech of a word in a sentence will help you better understand the meaning of a sentence.\n",
        "\n",
        "**Steps of POS:**\n",
        "*   Learn how parts-of-speech tagging works\n",
        "*    Compute the transition matrix A in a Hidden Markov Model.\n",
        "*    Compute the emission matrix B in a Hidden Markov Model.\n",
        "*    Compute the Viterbi algorithm.\n",
        "*    Compute the accuracy of your own model.\n"
      ],
      "metadata": {
        "id": "9rhzm6zinPSg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing on the main text files to get the taged words"
      ],
      "metadata": {
        "id": "1rPjwe9yo6iQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.corpus import gutenberg\n",
        "\n",
        "corpus = gutenberg.raw('/content/hmm_vocab.txt')\n",
        "tokenized = sent_tokenize(corpus)\n",
        "for i in tokenized:\n",
        "  words = nltk.word_tokenize(i)\n",
        "  tagged_text = nltk.pos_tag(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXrzRl9xo334",
        "outputId": "7e5928d4-c7fa-4548-c612-8a05a95420db"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## working with rtaining corpus:"
      ],
      "metadata": {
        "id": "VEOPPxXdrqtZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8M3GBT1gBdc",
        "outputId": "70dbefb3-2ae5-4f96-b3fd-5b262b7d082e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Few items of the training corpus list \n",
            "['In\\tIN\\n', 'an\\tDT\\n', 'Oct.\\tNNP\\n', '19\\tCD\\n', 'review\\tNN\\n']\n"
          ]
        }
      ],
      "source": [
        "# Load the training corpus\n",
        "\n",
        "with open(\"/content/WSJ_02-21(1).pos\", 'r') as file:\n",
        "  training_corpus = file.readlines()\n",
        "\n",
        "print(f'Few items of the training corpus list ')\n",
        "print(training_corpus[0:5])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read the vocabulary data, split by each line of text, and save the list\n",
        "with open('/content/hmm_vocab.txt', 'r') as f:\n",
        "  vocabulary = f.read().split('\\n')\n",
        "print(vocabulary[:5])"
      ],
      "metadata": {
        "id": "xuhPnF91iI2U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2f587a7-ef06-48f1-b3a6-1cff2aefdadf"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['!', '#', '$', '%', '&']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vocab: dictionary that has the index of the corresponding words\n",
        "vocab = {}\n",
        "#get the index of the corresponding words\n",
        "for i, word in enumerate(sorted(vocabulary)):\n",
        "  vocab[word] = i\n"
      ],
      "metadata": {
        "id": "ytZCC3_pjOv8"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Working with test data"
      ],
      "metadata": {
        "id": "Wokvx1lBsJ_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the test corpus\n",
        "with open('/content/WSJ_24.pos', 'r')as file:\n",
        "  testing_corpus = file.readlines()          #the testing_corpus\n",
        "\n",
        "print(testing_corpus[0:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1etzI9xj5Ny",
        "outputId": "0a70b6e5-0020-47c5-86e9-9c7c07f4d2b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The\\tDT\\n', 'economy\\tNN\\n', \"'s\\tPOS\\n\", 'temperature\\tNN\\n', 'will\\tMD\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#corpus without tags, preprocessed\n",
        "from utils_pos import preprocess, get_word_tag\n",
        "_, prep = preprocess(vocab, \"/content/test.words\")     \n",
        "\n",
        "print('The length of the preprocessed test corpus: ', len(prep))\n",
        "print('This is a sample of the test_corpus: ')\n",
        "print(prep[0:10])"
      ],
      "metadata": {
        "id": "WO3K6Bz6kIK-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f254663-4ec3-4119-9a12-656a8e7a6294"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of the preprocessed test corpus:  34199\n",
            "This is a sample of the test_corpus: \n",
            "['The', 'economy', \"'s\", 'temperature', 'will', 'be', 'taken', 'from', 'several', '--unk--']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 1: Parts-of-speech tagging**\n",
        "\n",
        "## Part 1.1 - Training\n",
        "\n",
        "You will start with the simplest possible parts-of-speech tagger and we will build up to the state of the art.\n",
        "\n",
        "In this section, you will find the words that are not ambiguous\n",
        "\n",
        "We need to compute:\n",
        "1.    The transition_counts dictionary: which computes the number of times each tag happened next to another tag.\n",
        "2.   The emission_counts:  will use it to compute the probability of a word given its tag. \n",
        "3.   The tag_counts:  the number of times each tag appeared.\n",
        "\n"
      ],
      "metadata": {
        "id": "VLFuD_mItwNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "Q-WOlnNVvNy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dictionaries(training_corpus, vocab, verbose=True):\n",
        "  # Intialize the dictionaries using defaultdict\n",
        "  emission_counts = defaultdict(int)\n",
        "  transition_counts = defaultdict(int)\n",
        "  tag_counts = defaultdict(int)\n",
        "\n",
        "  # Initialize the previous tag with the start state\n",
        "  prev_tag = '--s--'\n",
        "  # use i to track the line number in the corpus\n",
        "  i=0\n",
        "\n",
        "  for word_tag in training_corpus:\n",
        "    i += 1\n",
        "    word, tag = get_word_tag(word_tag, vocab)   # get the tag for each word from the vocabulary\n",
        "    transition_counts[(prev_tag, tag)] += 1\n",
        "    emission_counts[(tag, word)] += 1\n",
        "    tag_counts[tag] += 1\n",
        "    prev_tag = tag\n",
        "  return emission_counts, transition_counts, tag_counts"
      ],
      "metadata": {
        "id": "8KRMlzhNtaXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "def print_matrix(matrix):\n",
        "    print(pd.DataFrame(matrix, index=sorted_tags, columns=sorted_tags))\n"
      ],
      "metadata": {
        "id": "_58874lvxMUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emission_counts, transition_counts, tag_counts = create_dictionaries(training_corpus, vocab)"
      ],
      "metadata": {
        "id": "e4CnTKVjvwVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get all the POS states\n",
        "states = sorted(tag_counts.keys())\n",
        "print(f\"Number of POS tags (number of 'states'): {len(states)}\")\n",
        "print(\"View these POS tags (states)\")\n",
        "print(states)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jemN_xMJwlXc",
        "outputId": "a525369d-7f57-487b-bb39-4c7c873dfb8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of POS tags (number of 'states'): 46\n",
            "View these POS tags (states)\n",
            "['#', '$', \"''\", '(', ')', ',', '--s--', '.', ':', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB', '``']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"transition examples: \")\n",
        "for ex in list(transition_counts.items())[:3]:\n",
        "    print(ex)\n",
        "print()\n",
        "\n",
        "print(\"emission examples: \")\n",
        "for ex in list(emission_counts.items())[200:203]:\n",
        "    print (ex)\n",
        "print()\n",
        "\n",
        "print(\"ambiguous word example: \")\n",
        "for tup,cnt in emission_counts.items():\n",
        "    if tup[1] == 'back': print (tup, cnt) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xS1ua_wx2WX",
        "outputId": "6c1d46cd-7cef-4945-d4f6-5dfe4743a27c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transition examples: \n",
            "(('--s--', 'IN'), 5050)\n",
            "(('IN', 'DT'), 32364)\n",
            "(('DT', 'NNP'), 9044)\n",
            "\n",
            "emission examples: \n",
            "(('DT', 'any'), 721)\n",
            "(('NN', 'decrease'), 7)\n",
            "(('NN', 'insider-trading'), 5)\n",
            "\n",
            "ambiguous word example: \n",
            "('RB', 'back') 304\n",
            "('VB', 'back') 20\n",
            "('RP', 'back') 84\n",
            "('JJ', 'back') 25\n",
            "('NN', 'back') 29\n",
            "('VBP', 'back') 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Part 1.2 - Testing**\n",
        "\n",
        "Now you will test the accuracy of your parts-of-speech tagger using your emission_counts dictionary. "
      ],
      "metadata": {
        "id": "mslzv3E_yJzn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_pos(prep, testing_corpus, emission_counts, vocab, state):\n",
        "  # prep: is the preprocessed test corpus\n",
        "  num_correct = 0\n",
        "  all_words = set(emission_counts.keys())       # Get the (tag, word) tuples, stored as a set\n",
        "  total_testwords = len(testing_corpus)\n",
        "  for word, test_tuple in zip(prep, testing_corpus):\n",
        "    # Split the (word, POS) string into a list of two items\n",
        "    testing_tup1 = test_tuple.split()\n",
        "\n",
        "    # Verify that y_tup contain both word and pos\n",
        "    if len(testing_tup1) == 2:\n",
        "      # Set the true POS label for this word\n",
        "      true_label = testing_tup1[1]\n",
        "    else:\n",
        "      continue\n",
        "\n",
        "    count_final = 0\n",
        "    pos_final = 0\n",
        "\n",
        "    if word in vocab:\n",
        "      for pos in state:\n",
        "        key = (pos, word)\n",
        "        if key in emission_counts:\n",
        "          # get the emission count of the (pos,word) tuple\n",
        "          count = emission_counts[key]\n",
        "          if count > count_final:\n",
        "            count_final =count\n",
        "            pos_final = pos\n",
        "\n",
        "      if pos_final == true_label:\n",
        "        num_correct += 1\n",
        "\n",
        "  accuracy = num_correct / total_testwords\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "EkyLMcEEx_aG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_predict_pos = predict_pos(prep, testing_corpus, emission_counts, vocab, states)\n",
        "print(f\"Accuracy of prediction using predict_pos is {accuracy_predict_pos:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MLftmJj0a6_",
        "outputId": "793ba344-c6d0-444f-9b80-3673d707c8b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of prediction using predict_pos is 0.8889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 2.1 Generating Matrices**\n",
        "## **Creating the 'A' transition probabilities matrix:**\n",
        "\n",
        "Now that you have your emission_counts, transition_counts, and tag_counts, you will start implementing the Hidden Markov Model.\n",
        "\n",
        "This will allow you to quickly construct the\n",
        "*    A transition probabilities matrix.\n",
        "*    and the B emission probabilities matrix.\n",
        "\n",
        "You will also use some smoothing when computing these matrices"
      ],
      "metadata": {
        "id": "dd0VkjU72dCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_transition_matrix(alpha, tag_counts, transition_counts):\n",
        "  #alpha: number used for smoothing\n",
        "  all_tags = sorted(tag_counts.keys())  #get a sorted list of unique POs tags\n",
        "  num_tags = len(all_tags)              #count the number of unique POStags\n",
        "\n",
        "  # Intialize the transition matrix A\n",
        "  A = np.zeros((num_tags, num_tags))\n",
        "\n",
        "  # Get the unique transition tuples (previous POS, current POS)\n",
        "  trans_keys = set(transition_counts.keys())\n",
        "\n",
        "  for i in range(num_tags):\n",
        "    for j in range(num_tags):\n",
        "      count = 0\n",
        "      key = (all_tags[i], all_tags[j])\n",
        "      if key in transition_counts:\n",
        "        count = transition_counts[key]  #Nomenator\n",
        "      \n",
        "      count_prev_tag = tag_counts[key[0]]    # Domenator\n",
        "      A[i,j] = (count + alpha) / (count_prev_tag + alpha*num_tags)\n",
        "  \n",
        "  return A"
      ],
      "metadata": {
        "id": "8cj7ObyZ0dyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.001\n",
        "A = create_transition_matrix(alpha, tag_counts, transition_counts)\n",
        "# Testing your function\n",
        "print(f\"A at row 0, col 0: {A[0,0]:.9f}\")\n",
        "print(f\"A at row 3, col 1: {A[3,1]:.4f}\")\n",
        "\n",
        "print(\"View a subset of transition matrix A\")\n",
        "A_sub = pd.DataFrame(A[30:35,30:35], index=states[30:35], columns = states[30:35] )\n",
        "print(A_sub)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaNQ7N7g7urI",
        "outputId": "d16e5044-a4f5-4d8e-dc05-6da1d3cc207d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A at row 0, col 0: 0.000007040\n",
            "A at row 3, col 1: 0.1691\n",
            "View a subset of transition matrix A\n",
            "              RBS            RP           SYM        TO            UH\n",
            "RBS  2.217069e-06  2.217069e-06  2.217069e-06  0.008870  2.217069e-06\n",
            "RP   3.756509e-07  7.516775e-04  3.756509e-07  0.051089  3.756509e-07\n",
            "SYM  1.722772e-05  1.722772e-05  1.722772e-05  0.000017  1.722772e-05\n",
            "TO   4.477336e-05  4.472863e-08  4.472863e-08  0.000090  4.477336e-05\n",
            "UH   1.030439e-05  1.030439e-05  1.030439e-05  0.061837  3.092348e-02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Create the 'B' emission probabilities matrix:**"
      ],
      "metadata": {
        "id": "rFbKTgZJ797q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_emission_matrix(alpha, tag_counts, emission_counts, vocab):\n",
        "  num_tags = len(tag_counts)\n",
        "  all_tags = sorted(tag_counts.keys())\n",
        "  num_words = len(vocab)\n",
        "\n",
        "  B = np.zeros((num_tags, num_words))\n",
        "  emis_keys = set(list(emission_counts.keys()))\n",
        "  for i in range(num_tags):\n",
        "    for j in range(num_words):\n",
        "      count = 0\n",
        "      key = (all_tags[i], vocab[j])\n",
        "      for key in emission_counts:\n",
        "        count = emission_counts[key]\n",
        "        count_prev_tag = tag_counts[key[0]]\n",
        "        B[i,j] = (count + alpha) / (count_prev_tag + alpha*num_tags)\n",
        "  return B"
      ],
      "metadata": {
        "id": "K9djYG8e7x2u"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating your emission probability matrix. this takes a few minutes to run. \n",
        "alpha = 0.001\n",
        "B = create_emission_matrix(alpha, tag_counts, emission_counts, list(vocab))\n",
        "\n",
        "print(f\"View Matrix position at row 0, column 0: {B[0,0]:.9f}\")\n",
        "print(f\"View Matrix position at row 3, column 1: {B[3,1]:.9f}\")\n",
        "\n",
        "# Try viewing emissions for a few words in a sample dataframe\n",
        "cidx  = ['725','adroitly','engineers', 'promoted', 'synergy']\n",
        "\n",
        "# Get the integer ID for each word\n",
        "cols = [vocab[a] for a in cidx]\n",
        "\n",
        "# Choose POS tags to show in a sample dataframe\n",
        "rvals =['CD','NN','NNS', 'VB','RB','RP']\n",
        "\n",
        "# For each POS tag, get the row number from the 'states' list\n",
        "rows = [states.index(a) for a in rvals]\n",
        "\n",
        "# Get the emissions for the sample of words, and the sample of POS tags\n",
        "B_sub = pd.DataFrame(B[np.ix_(rows,cols)], index=rvals, columns = cidx )\n",
        "print(B_sub)"
      ],
      "metadata": {
        "id": "79xl1lrt-nlQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "outputId": "b4fed8cb-1bbf-41c8-cedd-6952599349f3"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-a90e0ed017f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# creating your emission probability matrix. this takes a few minutes to run.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_emission_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag_counts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memission_counts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"View Matrix position at row 0, column 0: {B[0,0]:.9f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-73-e2642ded1f42>\u001b[0m in \u001b[0;36mcreate_emission_matrix\u001b[0;34m(alpha, tag_counts, emission_counts, vocab)\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mall_tags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0memission_counts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memission_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mcount_prev_tag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mB\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcount_prev_tag\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnum_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}